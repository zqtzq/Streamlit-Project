import json
from langchain.schema import Document
from helper_functions.llm import *
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA

# Load the JSON file as a list of dictionaries
file_path = r'C:\Users\ASUS\Documents\ABC Bootcamp 2024 (Govtech)\Streamlit Project\scraped_content_old.json'
with open(file_path, 'r') as f:
    data = json.load(f)  # Load JSON data into a list of dictionaries

# Initialize an empty list to store Document objects
documents = []

# Loop through each dictionary in the JSON list
for item in data:
    # Create a Document with content and associated metadata
    doc = Document(
        page_content=item.get('content', ''),  # Extract the 'content' field
        metadata={
            "url": item.get("url", ""),
            "depth": item.get("depth", ""),
            "type": item.get("type", "")
        }
    )
    documents.append(doc)

# A simple in-memory vector search function (you can enhance this with a more sophisticated search mechanism)
def simple_retriever(query):
    # This is a placeholder for an actual retrieval mechanism.
    # You can implement a simple keyword search or other logic as needed.
    relevant_docs = []
    for doc in documents:
        if query.lower() in doc.page_content.lower():
            relevant_docs.append(doc)
    return relevant_docs

def process_user_message(user_input):
    # Build prompt
    template = """Use the following pieces of context to answer the question at the end.
    If you don't know the answer, just say that you don't know, don't try to make up an answer.
    Your answer should be clear and succinct.
    {context}
    Question: {question}
    Helpful Answer:"""
    QA_CHAIN_PROMPT = PromptTemplate.from_template(template)

    # Retrieve relevant documents using the simple retriever
    retrieved_documents = simple_retriever(user_input)

    # If no documents are found, return a default response
    if not retrieved_documents:
        return "I don't know the answer to that question."

    # Concatenate the content of the retrieved documents for the prompt
    context = "\n".join([doc.page_content for doc in retrieved_documents])

    # Run chain
    qa_chain = RetrievalQA.from_chain_type(
        ChatOpenAI(model='gpt-4o-mini'),
        retriever=lambda: context,  # Use the context for answering
        return_source_documents=True,  # Make inspection of document possible
        chain_type_kwargs={"prompt": QA_CHAIN_PROMPT}
    )

    reply = qa_chain.invoke(user_input)

    return reply
